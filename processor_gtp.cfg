# KataHex GTP Configuration for SGFS Processor
# Optimized for fast batch evaluation of positions

# ===========================================================================
# Logs and files
# ===========================================================================
logDir = processor_logs
logAllGTPCommunication = false
logSearchInfo = false
logToStderr = false

# ===========================================================================
# Rules
# ===========================================================================
rules = tromp-taylor

# ===========================================================================
# Bot behavior
# ===========================================================================

# Disable resignation for evaluation (we want raw NN output)
allowResignation = false
resignThreshold = -0.95

# ===========================================================================
# Search limits
# ===========================================================================
# For raw NN evaluation, we don't need search
# Set to minimal values for fastest evaluation

# Use 1600 visits for raw NN evaluation (no MCTS search)
maxVisits = 1

# Disable pondering
ponderingEnabled = false

# ===========================================================================
# Performance settings
# ===========================================================================

# Number of analysis threads (for analysis mode)
# This controls how many positions can be analyzed in parallel
numAnalysisThreads = 1

# Number of search threads per analysis thread
# For raw NN evaluation, 1 thread is sufficient
numSearchThreadsPerAnalysisThread = 1

# ===========================================================================
# GPU/CPU settings
# ===========================================================================

# Eigen (CPU) specific settings
# Number of CPU threads for NN evaluation
numEigenThreadsPerModel = 4

# Neural network cache size
# Smaller cache for batch processing to save memory
nnCacheSizePowerOfTwo = 18

# Size of mutex pool for nnCache is 2 ** this
nnMutexPoolSizePowerOfTwo = 16

# Maximum batch size for neural network evaluation
# For CPU (Eigen backend), this is automatically set to 4
# For GPU backends (CUDA/OpenCL), this should be set based on GPU memory
nnMaxBatchSize = 64

# Randomize board orientation when running neural net evals
nnRandomize = true

# ===========================================================================
# Internal params
# ===========================================================================

# Disable randomization for consistent evaluation
# nnRandomize = false
